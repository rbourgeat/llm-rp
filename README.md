# ğŸ“– LLM RP

<p align="center">
<a href="https://github.com/psf/black"><img alt="Code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg"></a>
<a href="https://github.com/psf/black"><img src="https://github.com/rbourgeat/llm-rp/actions/workflows/pylint.yml/badge.svg"></a>
</p>

<p align="center">
Your Custom Offline Role Play with AI on Mac and Linux (for now).
</p>

![LLM RP](llm-rp.png)

## ğŸ“ Requirement

For now:
- Python >= 3.8
- Mac: `pip install -r requirements.txt && pip install coremltools`
- Linux: `pip install -r requirements.txt`
- Install `git lfs`

## ğŸ‘‰ğŸ» Start

Each time you want to run the game:

```bash
python3 app/run.py
```

The first time you load the app you will wait a while,
because the program will download, export and quantize 
the better llama model for your config.

Next open your browser at http://127.0.0.1:5000

Click on the ğŸ—‘ï¸ for reset le Role Play

You can customize the prompt `prompts/RolePlay.txt`

## ğŸ“ Todo

- ğŸ’¾ Create a persistent role play (with save system)
- ğŸ–¼ï¸ Adding Stable Diffusion
- ğŸ› ï¸ Compile for GPU Linux / GPU Windows
- ğŸ¤ Adding [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- ğŸ”‰ Adding [Bark](https://github.com/suno-ai/bark) or an other Text-Prompted Generative Audio Model
- ğŸ”¥ Doing a better interface
- ğŸ”’ Lock user input when model generating response

## ğŸ” Sources

- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [WizardLM](https://huggingface.co/ehartford/)
